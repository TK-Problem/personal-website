[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "One-Sample Binomial Test (Part 1)\n\n\n\n\n\n\n\nR\n\n\nPython\n\n\nStatistics\n\n\n\n\n\n\n\n\n\n\n\nInvalid Date\n\n\nTomas Kristijonas Uždavinys\n\n\n\n\n\n\n  \n\n\n\n\nExports in Lithuania\n\n\n\n\n\n\n\nR\n\n\nMacro Economy\n\n\nCoursera\n\n\n\n\n\n\n\n\n\n\n\nMar 11, 2023\n\n\nTomas Kristijonas Uždavinys\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tomas K. Uždavinys",
    "section": "",
    "text": "I am a physics scientist who became a Python developer and risk analyst. My principal expertise is in writing predictive models, web scraping and automation scripts. I also have a passion to explain complicated topics in an easy-to-understand manner."
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Tomas K. Uždavinys",
    "section": "Experience",
    "text": "Experience\nQuantitative Risk Analyst | SEB | 2022 JAN - Present\nFreelancer | MB “Kristaulitai” | 2019 JAN - Present"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Tomas K. Uždavinys",
    "section": "Education",
    "text": "Education\nKTH - Royal institute of technology | PhD, Photonics | 2014 SEP - 2018 AUG\nVilnius University | M.S., Optoelectronic materials and technology | 2012 SEP - 2014 AUG"
  },
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "Portfolio",
    "section": "",
    "text": "PhD thesis [download PDF]\nPhD defense [recording on YouTube]"
  },
  {
    "objectID": "portfolio.html#papers",
    "href": "portfolio.html#papers",
    "title": "Portfolio",
    "section": "Papers",
    "text": "Papers\n\nS. Marcinkevičius, T. K. Uždavinys, H. M. Foronda, D. A. Cohen, C. Weisbuch, and J. S. Speck, “Intervalley energy of GaN conduction band measured by femtosecond pump-probe spectroscopy”, Phys. Rev. B 94, 235205 (2016)\nT. K. Uždavinys, S. Marcinkevičius, J. H. Leach, K. R. Evans, and D. C. Look, “Photoexcited carrier trapping and recombination at Fe centers in GaN”, J. Appl. Phys. 119, 215706 (2016)\nR. Butté, L. Lahourcade, T. K. Uždavinys, G. Callsen, M. Mensi, M. Glauser, G. Rossbach, D. Martin, J-F. Carlin, S. Marcinkevičius and N. Grandjean, “Optical absorption edge broadening in thick In- GaN layers: Random alloy atomic disorder and growth mode induced fluctuations”, Appl. Phys. Lett., 112, 032106 (2018).\nT. K. Uždavinys, S. Marcinkevičius, M. Mensi, L. Lahourcade, J-F. Carlin, D. Martin, R. Butté and N. Grandjean, “Impact of surface morphology on properties of light emission in InGaN epilayers”, Appl. Phys. Express 11, 051004 (2018).\nR. Ivanov, S. Marcinkevičius, T. K. Uždavinys, L. Y. Kuritzky, S. Nakamura, and J. S. Speck, “Scanning near-field microscopy of carrier lifetimes in m-plane InGaN quantum wells”, Appl. Phys. Lett. 110, 031109 (2017).\nT. K. Uždavinys, D. L. Becerra, R. Ivanov, S. P. DenBaars, S. Nakamura, J. S. Speck, and S. Marcinkevičius, “Influence of well width fluctuations on recombination properties in semipolar InGaN quantum wells studied by time- and spatially-resolved near-field photoluminecence”, Opt. Mat. Express, 7(9), 3116-3123 (2017)."
  },
  {
    "objectID": "posts/binom-test-1/index.html",
    "href": "posts/binom-test-1/index.html",
    "title": "One-Sample Binomial Test (Part 1)",
    "section": "",
    "text": "The binomial test is a statistical test used to determine whether the proportion of cases in one of only two categories is equivalent to a pre-specified proportion. Categories could include the default rate of clients within the next 12 months, patients with high or low risk of heart disease, potential customers who are likely or not likely to make a purchase, or the rate of manufacturing defects. This widely used test finds applications in diverse fields, including credit risk, medicine, and manufacturing. It is also known to as the one-sample proportion test or test of one proportion.\nAs with all statistical tests, the binomial test has assumptions and conditions that must be met before applying it to real-life data:\n\nThe “success-failure” condition requires observing a minimum of n successes and n failures in the sample;\nobservations are independent, i.e. the occurrence of one event does not affect the probability of occurrence of the other.\n\nThe aim of this blog post is to showcase the ramifications of failing to meet “success-failure” condition critereon. Practical examples are coded in both R and Python languages.\n\nRPython\n\n\n\n\nCode\n# load libraries for blog post\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(data.table)\nlibrary(kableExtra)\nlibrary(RColorBrewer) # for generating color palettes\n\n\n\n\n\n\nCode\n# load packages for blog post\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nfrom scipy.stats import binom, norm\n\n# set style\nplt.style.use(\"ggplot\")"
  },
  {
    "objectID": "posts/binom-test-1/index.html#theory",
    "href": "posts/binom-test-1/index.html#theory",
    "title": "One-Sample Binomial Test (Part 1)",
    "section": "Theory",
    "text": "Theory\nSuppose that we have a sample where outcomes are binary - e.g. only “success” and “failure”. For the given sample, we would like to estimate the true proportion and also set up a statistical test to verify whether if the proportion is equal to some value, e.g. expected.\nFirst, we calculate a point estimate:\n\\[p = \\frac{n_s}{n}\\]\n, where \\(n\\) - sample size and \\(n_s\\) - the number of successful observations (or it can be the number of failures).\n\\[SE = \\sqrt{\\frac{p \\cdot (1 - p)}{n}}\\] , where \\(SE\\) is standard error. To perform a test, one first needs to derive a Null hypothesis:\n\\[H_0: p = p_0\\]\nand an alternative hypothesis:\n\none-sided \\(H_A: p < p_0\\) or \\(H_A: p > p_0\\),\ntwo-sided \\(H_A: p \\ne p_0\\).\n\nFinally, we needs to calculate \\(Z\\) statistics:\n\\[Z = \\frac{p_0-p}{SE}\\]\nObtaining the value of \\(Z\\) enables us to either compute confidence intervals (\\(CI\\)) or reject \\(H_0\\) in favor of \\(H_A\\)"
  },
  {
    "objectID": "posts/binom-test-1/index.html#success-failure-condition",
    "href": "posts/binom-test-1/index.html#success-failure-condition",
    "title": "One-Sample Binomial Test (Part 1)",
    "section": "“Success-failure” condition",
    "text": "“Success-failure” condition\nTo approximate any distribution as normal, it is imperative to calculate the mean (\\(\\mu\\)) and standard deviation (\\(\\sigma\\)). For the Binomial distribution, which consists of a number of experiments \\(n\\) and a probability \\(p\\), the mean of the normal distribution is:\n\\[\\mu = n \\cdot p\\]\nand the standard deviation:\n\\[\\sigma = \\sqrt{n \\cdot p \\cdot (1 - p)}.\\]\nMeeting the “Success-Failure” condition is crucial to approximate Binomial distribution as Normal. Below, I present an instance of 50 Binomial events with varying probability rates of 5%, 30%, and 90%. In tabs binomial vs normal binomial distributions are plotted against it’s normal distribution approximation.\n\nbinomial vs. normal (R)error (R)binomial vs. normal (Python)error (Python)\n\n\n\n\nCode\n# probabilities\np <- c(0.05, 0.3, 0.9)\n\n# successes\nx <- 0:50\n\n# create data.table\ndt <- CJ(p, x)\n\n# add size column\ndt[, size := 50]\n\n# add binomial probability\ndt[, Binomial := dbinom(x, size=size, prob=p) * 100]\n\n# create label column\ndt[, label := paste0(\"Prob: \", round(p*100),\n                     \"%, exp. successes \", round(p*size),\n                     \" exp. failures \", round((1-p)*size))]\n\n# calculate mean and standard deviation\ndt[, mu := size * p]\ndt[, st.dev := sqrt(p * (1 - p) * size)]\n\n# get norm distribution\ndt[, Normal := dnorm(x, mean=mu, sd = st.dev) * 100]\n\n# convert to ordered factor\ndt[, label := factor(label, levels=c(\"Prob: 5%, exp. successes 2 exp. failures 48\",\n                                     \"Prob: 30%, exp. successes 15 exp. failures 35\",\n                                     \"Prob: 90%, exp. successes 45 exp. failures 5\" ))]\n\n# reshape for plotting\ndt.plot <- melt(dt, id.vars = c(\"x\", \"label\"),\n                measure.vars = c(\"Binomial\", \"Normal\"),\n                variable.name = c(\"Type\"),\n                value.name = c('prob'))\n\n# create figure\nfig <- ggplot(dt.plot, aes(x, prob, color=Type)) + geom_point() + facet_wrap(~label, ncol = 1) + ylab(\"Probability, %\")\nfig\n\n\n\n\n\n\n\n\n\nCode\n# calculate error (use data.table from previous code chunk)\ndt[, Error := Binomial - Normal]\n\n# create figure\nfig <- ggplot(dt, aes(x, Error)) + geom_point() + facet_wrap(~label, ncol = 1) + ylab(\"Error (binom. - norm.), %\")\nfig\n\n\n\n\n\n\n\n\n\nCode\n# probabilities\np = [0.05, 0.3, 0.9]\n\n# successes\nx = np.arange(51)\n\n# create DataFrame with all combinations\ndf_1 = pd.DataFrame({'p': p})\ndf_2 = pd.DataFrame({'x': x})\n\n# create key for joining\ndf_1['key'] = 0\ndf_2['key'] = 0\n\n# perform cross join\ndf = df_1.merge(df_2, on='key', how='outer')\n\n# drop key column\ndel df['key']\n\n# add size value\ndf['size'] = 50\n\n# calculate binomial probability\ndf['Binomial'] = binom.pmf(df['x'], df['size'], df['p']) * 100\n \n# calculate mean and standard deviation\ndf['mu'] = df['size'] * df['p']\ndf['se'] = np.sqrt(df['p'] * (1 - df['p']) / df['size'])\ndf['std'] = np.sqrt(df['p'] * (1 - df['p']) * df['size'])\n\n# get norm distribution\ndf['Normal'] = df.apply(lambda x: norm.pdf(x['x'], x['mu'], x['std']) * 100, axis = 1)\n\n# create figure\nfig, ax = plt.subplots(3, 1, sharey=True)\n\n# iterate over probabilities\nfor i, _p in enumerate(p):\n  # select data for plotting\n  dt_plot = df.loc[df['p'] == _p].copy()\n  \n  # plot binomial and normal distributions\n  ax[i].plot(dt_plot['x'], dt_plot['Binomial'], \"o\", label='Binomial');\n  ax[i].plot(dt_plot['x'], dt_plot['Normal'], \"-\", label='Normal', linewidth=3);\n  \n  # add sub titles\n  ax[i].set_title(f\"Prob. {_p*100:.0f}% expected {50*_p:.0f} successes and {50*(1-_p):.0f} failures\", fontsize=8);\n\n# add labels\nax[1].set_ylabel(\"Probability, %\");\nax[2].set_xlabel(\"x\");\n\n# add legend and white background\nlegend = ax[1].legend(frameon = 1);\nframe = legend.get_frame();\nframe.set_color('white');\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nCode\n# calculate error (use DataFrame from previous code chunk)\ndf['Error'] = df.Binomial - df.Normal\n\n# create figure\nfig, ax = plt.subplots(3, 1, sharey=True)\n\n# iterate over probabilities\nfor i, _p in enumerate(p):\n  # select data for plotting\n  dt_plot = df.loc[df['p'] == _p]\n  \n  # plot binomial and normal distributions\n  ax[i].plot(dt_plot['x'], dt_plot['Error'], \"o\", color='k', markersize=3);\n  \n  # add sub titles\n  ax[i].set_title(f\"Prob. {_p*100:.0f}% expected {50*_p:.0f} successes and {50*(1-_p):.0f} failures\", fontsize=8);\n  \n# adjust limits for better readability\nax[0].set_ylim(-4.9, 4.9)\n\n# add labels\n\n\n(-4.9, 4.9)\n\n\nCode\nax[1].set_ylabel(\"Probability, %\")\nax[2].set_xlabel(\"x\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nOut of 3 examples, the “Success-Failure” criterion is only applicable for the case where p=30%. By examining the error tabs, one can see that there is an approximation error. This refers to the disparity between the probabilities calculated using the Binomial and Normal distribution approximations. In particular, for the examples where p is set to 5% or 90%, this error can result in an overestimation or underestimation by more than 2% for point estimates."
  },
  {
    "objectID": "posts/binom-test-1/index.html#estimating-approximation-error",
    "href": "posts/binom-test-1/index.html#estimating-approximation-error",
    "title": "One-Sample Binomial Test (Part 1)",
    "section": "Estimating approximation error",
    "text": "Estimating approximation error\nTo better understand approximation error, it’s important to consider the differences between the discrete binomial distribution and the continuous normal distribution. The binomial distribution represents the probability of getting k successes in n independent trials, each with probability p of success. Its probability space is bounded between 0 and k events, where k represents the number of attempts. In contrast, the normal distribution represents a continuous probability distribution of a random variable with an infinite range of possible values i.e. one can calculate probability to observer 2.5 successes after 10 trials. Furthermore, apart from the case where p=50%, the binomial distribution is not symmetrical, unlike the normal distribution. This means that the area under the curve on one side of the mean (expected number of successes) is not equal to the area under the curve on the other side.\nDue to these differences, approximating the binomial distribution using the normal distribution will result in an approximation error. This error will be calculated as the difference between the probabilities calculated using the two distributions. In order to visualize approximation error, I will use interactive charts generated by the plotly library/package. Custom plotting functions were created in R and Python.\n\nplot_ly function (R)plotly function (Python)\n\n\n\n\nCode\nPlotDistributions <- function(prob, size){\n  # create observation vector\n  if (prob < 0.5){\n    x <- 0:(size*prob*3)\n  } else {\n    x <- (size - 3 * size * (1 - prob)):size\n  }\n  \n  # get probabilities for both binomial and norm distributions\n  y.binom <- dbinom(x, size=size, prob=prob) * 100\n  y.norm <- dnorm(x, mean=size * prob, sd = sqrt(prob * (1 - prob) * size)) * 100\n  \n  # create data table for plotting\n  dt <- data.table(x = x,\n                   prob.binom = y.binom,\n                   prob.norm = y.norm)\n  \n  # add columns with hover information\n  dt[, text.1 := paste0('Point estimate probability<br>to observer exactly ', x,\n                        ' events is ', round(y.binom, 3), \"%\")]\n  dt[, text.2 := paste0('Point estimate probability<br>to observer exactly ', x,\n                        ' events is ', round(y.norm, 3), \"%\")]\n  dt[, text.3 := paste0('Point estimate error<br>to observer exactly ', x,\n                        ' events is ', round(y.binom - y.norm, 3), \"%\")]\n  # create figure\n  fig <- plot_ly(data = dt, type = 'scatter', mode = 'lines')\n  \n  # add traces\n  fig <- fig %>% add_trace(x = ~x, y = ~prob.norm, text = ~text.1,\n                           name = 'Normal',mode = 'lines',\n                           hoverinfo = 'text',\n                           line = list(color = \"#FF6666\", width = 5))\n  fig <- fig %>% add_trace(x = ~x, y = ~prob.binom, text = ~text.2,\n                           name = 'Binomial',mode = 'markers',\n                           hoverinfo = 'text',\n                           marker = list(color = \"#3399FF\", size = 12))\n  fig <- fig %>% add_trace(x = ~x, y = ~(prob.binom-prob.norm), text = ~text.3,\n                           name = 'Error',mode = 'lines+markers',\n                           hoverinfo = 'text',\n                           line = list(color = \"black\", width = 5),\n                           marker = list(color = \"black\", size = 12),\n                           visible = \"legendonly\") \n  \n  # update layout\n  fig <- fig %>% layout(title = paste0(\"p = \", round(prob*100), \"%, \", size, \" trials\"),\n                        xaxis = list(title = \"Observations\"),\n                        yaxis = list (title = \"Probability, %\"),\n                        hovermode = \"x unified\",\n                        legend=list(title=list(text='<b> Distributions </b>')))\n  # return figure\n  return(fig)\n}\n\n\n\n\n\n\nCode\n# create function for plotting distributions\ndef plot_distributions(prob, size):\n  # create observation vector\n  x = np.arange(int(size*prob*3))\n  \n  # get probabilities for both binomial and norm distributions\n  y_binom = binom.pmf(x, n=size, p=prob) * 100\n  \n  # calculate variance and sigma\n  variance = size * prob * (1 - prob)\n  sigma = np.sqrt(variance)\n  \n  y_norm = norm.pdf(x, loc = size * prob, scale = sigma) * 100\n  \n  # generate Data.Frame\n  df = pd.DataFrame({'x': x, 'binom': y_binom, 'norm': y_norm})\n  \n  # calculate error\n  df['error'] = df.binom - df.norm\n  error = df.binom - df.norm\n  \n  # generate hover messages\n  df['text_1'] = df.apply(lambda x: f'Point estimate probability<br>to observer exactly {x[\"x\"]:.0f} events is {x[\"binom\"]:.3f}%', axis = 1)\n  df['text_2'] = df.apply(lambda x: f'Point estimate probability<br>to observer exactly {x[\"x\"]:.0f} events is {x[\"norm\"]:.3f}%', axis = 1)\n  df['text_3'] = df.apply(lambda x: f'Point estimate error<br>to observer exactly {x[\"x\"]:.0f} events is {x[\"error\"]:.3f}%', axis = 1)\n  \n  # create figure\n  fig = go.Figure()\n  fig.add_trace(go.Scatter(x=x, y=y_norm, text = df['text_1'].values,\n                           mode='lines', name='Normal', hoverinfo = 'text',\n                           line=dict(color='#FF6666', width=5)))\n  fig.add_trace(go.Scatter(x=x, y=y_binom, text = df['text_2'].values,\n                           mode='markers', name='Binomial', hoverinfo = 'text',\n                           marker=dict(color='#3399FF', size=12)))\n  fig.add_trace(go.Scatter(x=x, y=error, text = df['text_3'].values,\n                           mode='markers', name='Error', hoverinfo = 'text',\n                           marker=dict(color='black', size=12),\n                           visible = \"legendonly\"))\n                           \n  # Edit the layout\n  fig.update_layout(title=f\"p = {prob*100:.1f}%, {size} trials\",\n                    xaxis_title='Observations',\n                    yaxis_title='Probability, %',\n                    template=\"ggplot2\",\n                    hovermode=\"x unified\")\n                   \n  return fig\n\n\n\n\n\nNext, I have provided examples using small probabilities of 99%, 95%, 0.5%, and 0.1% with either 5 expected failures or 5 expected successes. To view the distribution of errors, simply click on the error line on the chart legend.\n\n99.9% (R)99.5% (R)0.5% (Python)0.01% (Python)\n\n\n\n\nCode\n# return figure\nPlotDistributions(0.999, 5000)\n\n\n\n\n\n\n\n\n\n\nCode\n# return figure\nPlotDistributions(0.995, 1000)\n\n\n\n\n\n\n\n\n\n\nCode\n# use python helper function from above\nfig = plot_distributions(0.005, 1000)\nfig\n\n\n\n                        \n                                            \n\n\n\n\n\n\nCode\n# use python helper function from above\nfig = plot_distributions(0.001, 5000)\nfig\n\n\n\n                        \n                                            \n\n\n\n\n\nLet’s say we have a hypothetical model with a small probability of occurrence, such as a 0.5% chance of manufacturing defects or a 0.5% chance of clients defaulting on their credit obligations. To meet the “Success-Failure” condition for this model, we would need to collect at least 2000 observations, i.e. manufacture 2000 devices or issue credit to 2000 obligators. In the 0.5% (Python) tab, one can see that if we have only collected 1000 events and expect 5 failures/defaults, normal distribution approximation overestimates the probability for \\(\\ge5\\) and underestimates it for \\(\\le5\\), as evident from visual inspection and reviewing error estimates for different outcomes (select error line on legend to view error distribution). For cases then we are very certain, e.g. 99.9% (R), overestimation if for cases \\(\\le5\\) and underestimation for \\(\\ge5\\). From visual inspection, one can observe that the smaller the probability, the larger the error between point estimates becomes.\nLet’s try to quantify approximation error by calculating 3 probabilities using binomial and it’s approximation using normal distribution:\n\n\\(p_1\\) to observe expected number of occurrences,\n\\(p_2\\) to observe more than expected number of occurrences,\n\\(p_3\\) to observe less than expected number of occurrences.\n\nAfter calculating, these probabilities can be compared them by using ratios e.g. \\(ratio_1 = \\frac{p_1 (binom.)}{p_1 (norm.)}\\). In the table below, \\(p_1\\) probabilities calculated using different distributions are presented. I also provide all 3 ratios, which shows by how much normal distribution overestimates/underestimates binomial distribution. For all cases 5 successes/failures are expected.\n\n\nCode\n# generate data.table\ndt <- data.table(p = c(0.999, 0.995, 0.99, 0.95, 0.8,\n                       0.5,\n                       0.2, 0.05, 0.01, 0.005, 0.001),\n                 N = c(5000, 1000, 500, 100, 25,\n                       10,\n                       25, 100, 500, 1000, 5000))\n# expected events\ndt[, x := p * N]\n\n# get binomial, normal probabilities and their ratio\ndt[, binom.p1 := dbinom(x, size=N, prob=p) * 100]\ndt[, norm.p1 := dnorm(x, mean=N * p, sd = sqrt(p * (1 - p) * N)) * 100]\ndt[, ratio.1 := binom.p1/norm.p1 * 100]\n\n# calculate p2 probabilities\ndt[, binom.p2 := pbinom(x-1, size=N, prob=p) * 100]\ndt[, norm.p2 := (1-dnorm(x, mean=N * p, sd = sqrt(p * (1 - p) * N)))/2 * 100]\n\n# calculate p3 probabilities\ndt[, binom.p3 := (1 - pbinom(x, size=N, prob=p)) * 100]\n\n# calculate ratios\ndt[, ratio.2 := binom.p2/norm.p2 * 100]\ndt[, ratio.3 := binom.p3/norm.p2 * 100]\n\n# round columns for better readability\ncols <- names(dt)[4:11]\ndt[,(cols) := round(.SD, 3), .SDcols=cols]\n\n# convert probability to percents\ndt[, p := round(p * 100, 1)]\n\n# remove column\ndt$x <- NULL\n\n# generate table with first few rows and columns\nknitr::kable(dt[, c(1:5, 9, 10)], col.names = c(\"p, %\", \"N\", \"p1 (binom.), %\", \"p1 (norm.), %\", \"ratio 1\", \"ratio 2\", \"ratio 3\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n\n\n\n\n \n  \n    p, % \n    N \n    p1 (binom.), % \n    p1 (norm.), % \n    ratio 1 \n    ratio 2 \n    ratio 3 \n  \n \n\n  \n    99.9 \n    5000 \n    17.556 \n    17.850 \n    98.349 \n    93.497 \n    107.220 \n  \n  \n    99.5 \n    1000 \n    17.591 \n    17.886 \n    98.349 \n    93.538 \n    107.181 \n  \n  \n    99.0 \n    500 \n    17.635 \n    17.931 \n    98.349 \n    93.589 \n    107.132 \n  \n  \n    95.0 \n    100 \n    18.002 \n    18.305 \n    98.345 \n    94.008 \n    106.734 \n  \n  \n    80.0 \n    25 \n    19.602 \n    19.947 \n    98.267 \n    95.764 \n    105.099 \n  \n  \n    50.0 \n    10 \n    24.609 \n    25.231 \n    97.535 \n    100.832 \n    100.832 \n  \n  \n    20.0 \n    25 \n    19.602 \n    19.947 \n    98.267 \n    105.099 \n    95.764 \n  \n  \n    5.0 \n    100 \n    18.002 \n    18.305 \n    98.345 \n    106.734 \n    94.008 \n  \n  \n    1.0 \n    500 \n    17.635 \n    17.931 \n    98.349 \n    107.132 \n    93.589 \n  \n  \n    0.5 \n    1000 \n    17.591 \n    17.886 \n    98.349 \n    107.181 \n    93.538 \n  \n  \n    0.1 \n    5000 \n    17.556 \n    17.850 \n    98.349 \n    107.220 \n    93.497 \n  \n\n\n\n\n\nThere results show that when \\(p > 50\\%\\) overestimation is observed on the right-hand side of distribution and opposite is true for \\(p < 50\\%\\). The ratio between \\(p_1\\) probabilities is the same across all examples - it is defined by number of expected outcomes and not probability. Overestimation \\(ratio_2>100\\%\\) are the same for \\(p > 50\\%\\) cases as underestimation \\(ratio_3<100\\%\\). As implied probability becomes closer to 50%, the binomial distribution becomes more symmetrical so both \\(ratio_2\\) and \\(ratio_3\\) becomes closer to 100%.\nAnother way to measure approximation error is to calculate the total absolute approximation error, which is obtained by subtracting the normal distribution approximation from the binomial distribution approximation. The reason for using total error instead of the mean absolute error is that for the latter calculations are affected by very small errors at the edge of distributions. The key idea is that as the number of observations, i.e. the expected number of successes/failures increases, the total error between point estimates will decrease. Similar to the previous example, the total approximation error is calculated for the same probabilities with 5 expected successes/failures.\n\n\nCode\n# generate data.table\ndt <- data.table(p = c(0.999, 0.995, 0.99, 0.95, 0.8,\n                       0.5,\n                       0.2, 0.05, 0.01, 0.005, 0.001),\n                 N = c(5000, 1000, 500, 100, 25,\n                       10,\n                       25, 100, 500, 1000, 5000))\n# expected events\ndt[, x := p * N]\n\n# ugly, but quick way to calculate approximation error\nfor (p.tmp in dt$p){\n  # generate vector\n  x.vect <- 0:dt[p == p.tmp, N]\n  \n  # get probabilities for both binomial and norm distributions\n  y.binom <- dbinom(x.vect, dt[p == p.tmp, N], p.tmp)\n  y.norm <- dnorm(x.vect, mean=dt[p == p.tmp, N] * p.tmp, sd = sqrt(p.tmp * (1 - p.tmp) * dt[p == p.tmp, N]))\n  \n  # sum absolute error\n  y.err <- sum(abs(y.binom - y.norm))\n  \n  # add error term\n  dt[p == p.tmp, tot.abs.error := round(y.err*100, 3)]\n}\n\n# convert probability to percents\ndt[, p := round(p * 100, 1)]\n\n# remove column\ndt$x <- NULL\n\n# generate table with first few rows and columns\nknitr::kable(dt, col.names = c(\"p, %\", \"N\", \"Total absolute error, %\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n\n\n\n\n \n  \n    p, % \n    N \n    Total absolute error, % \n  \n \n\n  \n    99.9 \n    5000 \n    10.804 \n  \n  \n    99.5 \n    1000 \n    10.754 \n  \n  \n    99.0 \n    500 \n    10.691 \n  \n  \n    95.0 \n    100 \n    10.158 \n  \n  \n    80.0 \n    25 \n    7.686 \n  \n  \n    50.0 \n    10 \n    2.381 \n  \n  \n    20.0 \n    25 \n    7.686 \n  \n  \n    5.0 \n    100 \n    10.158 \n  \n  \n    1.0 \n    500 \n    10.691 \n  \n  \n    0.5 \n    1000 \n    10.754 \n  \n  \n    0.1 \n    5000 \n    10.804 \n  \n\n\n\n\n\nThe table above shows that the total point approximation error is the smallest when the probability is the largest (p=50%). However, for situations that are very likely, e.g. 99.9%, or very unlikely (0.1%), where we expect to see only a few successes or failures out of a large number of trials, approximating the binomial distribution with normal distribution can lead to more than 10% total point estimate error.\nNext, let’s compare cumulative probabilities for different examples based on both probabilities (p) and expected values (EV). To highlight commonly used two-sided null hypothesis rejection levels, I have added 95% confidence intervals (black dashed line) and 99% confidence intervals (red dashed line).\n\n0.1% (5 EV)10% (5 EV)10% (10 EV)20% (15 EV)50% (5 EV)50% (10 EV)50% (15 EV)80% (15 EV)90% (10 EV)99% (5 EV)99.9% (5 EV)\n\n\n\n\nCode\n# helper function for plotting\nvline <- function(x = 0, color = \"black\") {\n  list(\n    type = \"line\",\n    y0 = 0,\n    y1 = 1,\n    yref = \"paper\",\n    x0 = x,\n    x1 = x,\n    line = list(color = color, dash = \"dot\")\n  )\n}\n\n# helper function to draw cum. probabilities\nPlotCumProbs <- function(p, N){\n  \n  # for adjusting plot x limits\n  x.ratio <- p*N\n  \n  # create vector depending on probability\n  if (p <= 0.5){\n    if (N*p >= 10){\n      x <- 0:max((N*p*2), N*p)\n    } else {\n      x <- 0:max((N*p*3), N*p)\n    }\n  } else {\n    if (N*(1-p) >= 10){\n      x <- max((N - 2 * N * (1 - p)), 0):N\n    } else {\n      x <- max((N - 3 * N * (1 - p)), 0):N\n    }\n  }\n  \n  # calculate z values as events for different confidence intervals\n  Z.95.left <- (N * p - 1.960 * sqrt(p * (1 - p) * N))\n  Z.99.left <- (N * p - 2.576 * sqrt(p * (1 - p) * N))\n  Z.95.right <- (N * p + 1.960 * sqrt(p * (1 - p) * N))\n  Z.99.right <- (N * p + 2.576 * sqrt(p * (1 - p) * N))\n  \n  # calculate cum. probabilities for both binomial and normal distributions\n  y.binom <- pbinom(x, size=N, prob=p) * 100\n  y.norm <- pnorm(x, mean=N * p, sd = sqrt(p * (1 - p) * N)) * 100\n  \n  # create data.table for plotting\n  dt <- data.table(x = x, y.binom = y.binom, y.norm = y.norm)\n  \n  # calculate error\n  dt[, error := y.binom - y.norm]\n  \n  # add hover text messages\n  dt[, text.1 := paste0(round(y.binom, 3), \"%\")]\n  dt[, text.2 := paste0(round(y.norm, 3), \"%\")]\n  dt[, text.3 := paste0(round(error, 3), \"%\")]\n  \n  # create figure\n  fig <- plot_ly(data = dt, type = 'scatter', mode = 'lines')\n  \n  # add traces\n  fig <- fig %>% add_trace(x = ~x, y = ~y.norm, text = ~text.1,\n                           name = 'Normal',mode = 'lines',\n                           hoverinfo = 'text',\n                           line = list(color = \"#FF6666\", width = 5))\n  fig <- fig %>% add_trace(x = ~x, y = ~y.binom, text = ~text.2,\n                           name = 'Binomial',mode = 'markers',\n                           hoverinfo = 'text',\n                           marker = list(color = \"#3399FF\", size = 12))\n  fig <- fig %>% add_trace(x = ~x, y = ~error, text = ~text.3,\n                           name = 'Error',mode = 'lines+markers',\n                           hoverinfo = 'text',\n                           line = list(color = \"black\", width = 5),\n                           marker = list(color = \"black\", size = 12))\n  \n  # update layout\n  fig <- fig %>% layout(title = paste0(\"p = \", round(p*100, 1), \"%, \", N, \" trials (EV = \", x.ratio, \")\"),\n                        xaxis = list(title = \"Observations\"),\n                        yaxis = list (title = \"Probability, %\"),\n                        hovermode = \"x unified\",\n                        shapes = list(vline(Z.99.left, color='red'), vline(Z.95.left), vline(Z.95.right), vline(Z.99.right, color='red')),\n                        legend=list(title=list(text='<b> Distributions </b>')))\n  \n  # return figure object\n  return(fig)\n}\n\n# plot example for 0.1%\nPlotCumProbs(0.001, 5000)\n\n\n\n\n\n\n\n\n\n\nCode\n# plot example for 1%\nPlotCumProbs(0.01, 500)\n\n\n\n\n\n\n\n\n\n\nCode\n# plot example for 10%\nPlotCumProbs(0.1, 100)\n\n\n\n\n\n\n\n\n\n\nCode\n# plot example for 20%\nPlotCumProbs(0.2, 75)\n\n\n\n\n\n\n\n\n\n\nCode\n# plot example for 50%\nPlotCumProbs(0.5, 10)\n\n\n\n\n\n\n\n\n\n\nCode\n# plot example for 50%\nPlotCumProbs(0.5, 20)\n\n\n\n\n\n\n\n\n\n\nCode\n# plot example for 50%\nPlotCumProbs(0.5, 30)\n\n\n\n\n\n\n\n\n\n\nCode\n# plot example for 80%\nPlotCumProbs(0.8, 75)\n\n\n\n\n\n\n\n\n\n\nCode\n# plot example for 90%\nPlotCumProbs(0.9, 100)\n\n\n\n\n\n\n\n\n\n\nCode\n# plot example for 99%\nPlotCumProbs(0.99, 500)\n\n\n\n\n\n\n\n\n\n\nCode\n# plot example for 99.9%\nPlotCumProbs(0.999, 5000)\n\n\n\n\n\n\n\n\n\nThe first thing to note is that it’s not possible to test a 2-sided hypothesis for a low EV example. Take a look at the tabs with “(5 EV)” in their name - the red dashed lines fall outside the range of viable outcomes, except for 50% (5EV) case. In this example, if you conduct 10 trials and observe either 0 or 10 successes, you can reject the null hypothesis \\(H_0 \\ne p\\) with a 99% confidence interval. However, as the sample size increases i.e. one gets larger EV, the distribution widths become narrower. This means that 2-sided tests with a 99% confidence interval become viable for other probability values, as seen in the example with an 20% (15 EV). Additionally, when comparing distributions with the same EV but different probabilities, we see that the error between the binomial distribution and its approximation using the normal distribution is very similar."
  },
  {
    "objectID": "posts/binom-test-1/index.html#approximation-error-dynamics",
    "href": "posts/binom-test-1/index.html#approximation-error-dynamics",
    "title": "One-Sample Binomial Test (Part 1)",
    "section": "Approximation error dynamics",
    "text": "Approximation error dynamics\nFinally, let’s now explore how much \\(ratio_1\\) and total absolute approximation errors are affected by the sample size. In the examples below, the sample sizes were adjusted based on the number of expected successes/failures. For instance, to observe 5 EV with p=1%, one needs 500 observations and for p=20%, one needs 25 observations. However, this approach has some drawbacks, such as being difficult to normalize for specific cases. For example, to observe 7 EV with p=15%, one needs 46.66 observations. In such cases, the number of observations was rounded down to the nearest integer, resulting in some spiky line charts for these specific cases.\n\nRatio 1Approximation error\n\n\n\n\nCode\n# generate data.table with expected values and sample probabilities\nprobs <- c(0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.45, 0.5, 0.55, 0.6, 0.7, 0.8, 0.9, 0.99, 0.999)\ndt <- CJ(Sucesses = c(1:50), p = probs)\n\n# get probability and sample size for expected values\ndt[p <= 0.5, N := ceiling(Sucesses / p)]\ndt[p > 0.5, N := ceiling(Sucesses / (1 - p))]\n\n# get number of failures\ndt[, Failures := N - Sucesses]\n\n# calculate probabilities to observe expected number of observations \ndt[p <= 0.5, binom.p1 := dbinom(Sucesses, size = N, prob=p) * 100]\ndt[p > 0.5, binom.p1 := dbinom(Failures, size = N, prob=p) * 100]\ndt[p <= 0.5, norm.p1 := dnorm(Sucesses, mean = N * p, sd = sqrt(p * (1 - p) * N)) * 100]\ndt[p > 0.5, norm.p1 := dnorm(Failures, mean = N * p, sd = sqrt(p * (1 - p) * N)) * 100]\n\n# get ratio between point estimates\ndt[, ratio.1 := round(binom.p1/norm.p1 * 100, 3)]\n\n# for coloring get probability\ndt[, Probability := paste0(round(p * 100, 1), \"%\")]\n\n# text message for hover (decided not to use this column)\ndt[, text := paste0(Probability, \" with \", N, \" attempts: \", ratio.1)]\n\n# generate color palette\n# code example taken from\n# https://stackoverflow.com/questions/15282580/how-to-generate-a-number-of-most-distinctive-colors-in-r\nn <- length(probs)\nqual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]\ncol_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))\n\n# generate figure\nfig <- plot_ly(dt,\n               x = ~Sucesses,\n               y = ~ratio.1,\n               color = ~Probability,\n               colors = col_vector,\n               line = list(width = 4)) \nfig <- fig %>% add_lines()\n\n# with log scales\nfig <- layout(fig,\n              hovermode = \"x unified\",\n              yaxis = list(type = \"log\", title = \"Ratio 1, %\"),\n              xaxis = list(title = \"Expected sucessess/failures\"),\n              legend=list(title=list(text='<b> Probabilities </b>')))\n\nfig\n\n\n\n\n\n\n\n\n\n\nCode\n# generate data.table with expected values and sample probabilities\nprobs <- c(0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.45, 0.5, 0.55, 0.6, 0.7, 0.8, 0.9, 0.99, 0.999)\ndt <- CJ(Sucesses = c(1:100), p = probs)\n\n# get probability and sample size for expected values\ndt[p <= 0.5, N := ceiling(Sucesses / p)]\ndt[p > 0.5, N := ceiling(Sucesses / (1 - p))]\n\n# get number of failures\ndt[, Failures := N - Sucesses]\n\n# ugly, but quick way to calculate approximation error\nfor (idx in 1:nrow(dt)){\n  # generate vector\n  x.vect <- 0:dt[idx, N]\n  \n  # select probaiblity\n  p.tmp <- dt[idx, p]\n\n  # get probabilities for both binomial and norm distributions\n  y.binom <- dbinom(x.vect, dt[idx, N], p.tmp)\n  y.norm <- dnorm(x.vect, mean=dt[idx, N] * p.tmp, sd = sqrt(p.tmp * (1 - p.tmp) * dt[idx, N]))\n\n  # sum absolute error\n  y.err <- sum(abs(y.binom - y.norm))\n\n  # add error term\n  dt[idx, tot.abs.error := round(y.err*100, 3)]\n}\n\n# generate color palette\n# code example taken from\n# https://stackoverflow.com/questions/15282580/how-to-generate-a-number-of-most-distinctive-colors-in-r\nn <- length(probs)\nqual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]\ncol_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))\n\n# for coloring get probability\ndt[, Probability := paste0(round(p * 100, 1), \"%\")]\n\n# generate figure\nfig <- plot_ly(dt,\n               x = ~Sucesses,\n               y = ~tot.abs.error,\n               color = ~Probability,\n               colors = col_vector,\n               line = list(width = 4)) \nfig <- fig %>% add_lines()\n\n# with log scales\nfig <- layout(fig,\n              hovermode = \"x unified\",\n              yaxis = list(type = \"log\", title = \"Total absolute error, %\"),\n              xaxis = list(title = \"Expected sucessess/failures\"),\n              legend=list(title=list(text='<b> Probabilities </b>')))\n\nfig\n\n\n\n\n\n\n\n\n\nSurprisingly the \\(ratio_1\\) is inversely depended on probability - approximation error is the smallest for very likely or unluckily cases. The opposite is true for total absolute error - it is the smallest for p=50%. Even with 50 EV for small probabilities, i.e. 0.1% or 99.9% this error \\(>3.5\\%\\). The key take away is that if we are looking ar large confidence intervals (CI), i.e. 95% or 99%, then 10 EV is sufficient to test hypothesis. If we would like to establish some intermediate values between, then for small probabilities, number of observations to collect should increased."
  },
  {
    "objectID": "posts/binom-test-1/index.html#conclusions",
    "href": "posts/binom-test-1/index.html#conclusions",
    "title": "One-Sample Binomial Test (Part 1)",
    "section": "Conclusions",
    "text": "Conclusions\nOne should be very mindful when designing experiments for one-sample binomial test. Failing to meet “success-failure” condition would result in overestimation or underestimation of you \\(H_0\\) hypothesis results. For relatively large probabilities, 30%-70% one can use"
  },
  {
    "objectID": "posts/binom-test-1/index.html#references",
    "href": "posts/binom-test-1/index.html#references",
    "title": "One-Sample Binomial Test (Part 1)",
    "section": "References",
    "text": "References\nContent for this blog post was prepared using following resources:\n\nhttps://statistics.laerd.com/spss-tutorials/binomial-test-using-spss-statistics.php\nhttp://mlwiki.org/index.php/Binomial_Proportion_Tests\nhttps://sites.ualberta.ca/~lkgray/uploads/7/3/6/2/7362679/slides_-_binomialproportionaltests.pdf\nhttps://www.technologynetworks.com/informatics/articles/the-binomial-test-366022\nhttps://towardsdatascience.com/turning-a-two-sample-event-rate-test-into-a-one-sample-binomial-test-23fbfb9d1df6\nhttps://www.studysmarter.us/explanations/math/statistics/binomial-hypothesis-test/\nhttps://www.statology.org/success-failure-condition/\nhttps://towardsdatascience.com/bernoulli-and-binomial-random-variables-d0698288dd36\nhttps://ubc-mds.github.io/DSCI_551_stat-prob-dsci/lectures/simulation.html\nhttps://math.stackexchange.com/questions/1978138/probability-of-x-red-balls-when-drawing-y-balls-from-a-red-and-b-green-balls"
  },
  {
    "objectID": "posts/google-analytics-capstone/index.html",
    "href": "posts/google-analytics-capstone/index.html",
    "title": "Exports in Lithuania",
    "section": "",
    "text": "Hello and welcome to my first blog post on Quarto! As a part of my Google Data Analytics specialization course capstone project, I have created this blog. In this post, I will be exploring the changes in historical exports and imports of Lithuania over time, using the 6-step framework presented in the course. I hope you enjoy reading about my findings and analysis. Let’s begin!"
  },
  {
    "objectID": "posts/google-analytics-capstone/index.html#ask",
    "href": "posts/google-analytics-capstone/index.html#ask",
    "title": "Exports in Lithuania",
    "section": "Ask",
    "text": "Ask\nBefore diving into data processing and visualization, it’s essential to take note of the following key events: the Covid-19 pandemic since spring 2020, the strained relationship between China and Lithuania due to the Taiwan question, and the Russian invasion of Ukraine in 2022.\nThe Covid-19 pandemic has brought unprecedented changes to the global economy, and Lithuania was no exception. The outbreak caused major disruptions in global trade, resulting in a decline in demand for Lithuanian goods and services. On the other hand, Lithuania’s relationship with China has been deteriorating due to the Taiwan question. This has led to a decrease in exports to China, one of Lithuania’s top trading partners.\nThe Russian invasion of Ukraine in 2022 has also had a significant impact on Lithuania’s trade patterns. The conflict has resulted in the imposition of economic sanctions on Russia, affecting Lithuania’s trade with its Eastern neighbor. The situation is still developing, and it will be interesting to see how Lithuania’s trade with Russia evolves in the coming years."
  },
  {
    "objectID": "posts/google-analytics-capstone/index.html#prepare",
    "href": "posts/google-analytics-capstone/index.html#prepare",
    "title": "Exports in Lithuania",
    "section": "Prepare",
    "text": "Prepare\nThe data was downloaded from the Lithuanian National website in an Excel file format. You can also find the same file in my blog’s Github repo. It was then loaded into the R environment using the tidyverse library and converted to data.table format.\n\n\nCode\n# load libraries\nlibrary(readxl)\nlibrary(data.table)\nlibrary(kableExtra)\nlibrary(plotly)\nlibrary(zoo)\n\n# read data from excel\ndt <- read_excel(\"lb_data.xlsx\", sheet = 1, range = \"A13:AN201\")\n\n# convert to data.table object\ndt <- data.table(dt)\n\n# rename columns for convinience\nsetnames(dt, c(\"...1\"), \"Type\")\n\n# shift columns to get correct names\ndt[, Country := rep(dt[seq(1, nrow(dt), 4), Type], each = 4)]\ndt <- dt[!(seq(1, nrow(dt), 4))]\n\n# generate table with first few rows and columns\nkbl(dt[1:6, c(41, 1, 38, 39, 40)]) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n\n\n\n\n \n  \n    Country \n    Type \n    Q1/2022 \n    Q2/2022 \n    Q3/2022 \n  \n \n\n  \n    Total \n    Exports \n    3666.97 \n    4230.51 \n    4615.79 \n  \n  \n    Total \n    Imports \n    2417.61 \n    2585.59 \n    2814.54 \n  \n  \n    Total \n    Balance \n    1249.36 \n    1644.92 \n    1801.25 \n  \n  \n    European Union (27 countries) \n    Exports \n    2712.50 \n    3182.83 \n    3343.46 \n  \n  \n    European Union (27 countries) \n    Imports \n    1646.39 \n    1887.25 \n    2026.76 \n  \n  \n    European Union (27 countries) \n    Balance \n    1066.11 \n    1295.58 \n    1316.70 \n  \n\n\n\n\n\nIn the table above, you can see the total exports and imports of all countries, as well as those of the European Union’s (27 countries) for the three most recent quarters. Even before data cleaning and preparation, a visual analysis shows that a majority of exports and imports go to EU countries. Data is available about 41 unique countries."
  },
  {
    "objectID": "posts/google-analytics-capstone/index.html#process",
    "href": "posts/google-analytics-capstone/index.html#process",
    "title": "Exports in Lithuania",
    "section": "Process",
    "text": "Process\nFor this project, we didn’t need to do much data cleaning or processing since there were no missing values or unknown formats. However, we did make some minor formatting adjustments in the Prepare section. To keep things simple, I decided not to split this section into different parts."
  },
  {
    "objectID": "posts/google-analytics-capstone/index.html#analyze",
    "href": "posts/google-analytics-capstone/index.html#analyze",
    "title": "Exports in Lithuania",
    "section": "Analyze",
    "text": "Analyze\nAfter formatting and sorting the data, I investigated export changes of top 10 largest export destinations in 2003 Q3. Exports across European countries saw a substantial increase, with some countries experiencing growth rates of between 200-700%, exports to Belarus and Russia dropped significantly by 60% and 50%, respectively.\n\n\nCode\n# select exports data and exclude aggregated entires\nagg <- c(\"Total\", \"European Union (27 countries)\", \"Euro Area (18 countries)\", \"Commonwealth of Independent States\", \"Offshore financial centers\", \"Other countries\")\ndt.export <- copy(dt[Type == \"Exports\" & !Country %in% agg])\ndt.export[, `Change, %` := round((`Q3/2022` / `Q3/2013` - 1) * 100, 1)]\n# get top 10 starting and last period countries by export\nstart <- tail(dt.export[, c(41, 4, 40)][order(`Q3/2013`)], 10)\n# generate kable table\nkbl(start, caption = \"Top 10 largest export destinations in 2013 Q3\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n\n\n\n\nTop 10 largest export destinations in 2013 Q3\n \n  \n    Country \n    Q3/2013 \n    Q3/2022 \n  \n \n\n  \n    United Kingdom \n    44.43 \n    261.90 \n  \n  \n    Netherlands \n    44.60 \n    313.90 \n  \n  \n    Norway \n    46.59 \n    115.63 \n  \n  \n    France \n    47.51 \n    380.13 \n  \n  \n    Denmark \n    61.80 \n    214.14 \n  \n  \n    Latvia \n    78.22 \n    181.07 \n  \n  \n    Poland \n    80.27 \n    209.38 \n  \n  \n    Belarus \n    120.38 \n    45.89 \n  \n  \n    Germany \n    148.49 \n    637.61 \n  \n  \n    Russia \n    323.90 \n    154.09 \n  \n\n\n\n\n\nI found it interesting to observe that out of the 41 countries with known data, there were export reductions in only four countries: Egypt, Russia, Belarus, and Japan. Furthermore, I noticed that the largest export changes were seen in countries with relatively small exports in 2003 Q3, such as Croatia and Malta, whose exports increased 40 times. It’s worth noting that Canada, a large economy, also saw a significant increase in exports, which grew almost 30 times.\n\n\nCode\n# get top 10 starting and last period countries by export\ntop_change <- tail(dt.export[, c(41, 4, 40, 42)][order(`Change, %`)], 5)\nlow_change <- head(dt.export[, c(41, 4, 40, 42)][order(`Change, %`)], 5)\n\n# get changes\ndt.changes <- rbind(low_change, top_change)\n\n# generate kable table\nkbl(dt.changes, caption = \"Top 5 largest positive and negative export changes\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n\n\n\n\nTop 5 largest positive and negative export changes\n \n  \n    Country \n    Q3/2013 \n    Q3/2022 \n    Change, % \n  \n \n\n  \n    Egypt \n    4.65 \n    0.94 \n    -79.8 \n  \n  \n    Belarus \n    120.38 \n    45.89 \n    -61.9 \n  \n  \n    Russia \n    323.90 \n    154.09 \n    -52.4 \n  \n  \n    Japan \n    1.64 \n    1.21 \n    -26.2 \n  \n  \n    India \n    2.52 \n    3.03 \n    20.2 \n  \n  \n    Bulgaria \n    0.76 \n    13.92 \n    1731.6 \n  \n  \n    Canada \n    0.38 \n    11.62 \n    2957.9 \n  \n  \n    Romania \n    0.70 \n    27.03 \n    3761.4 \n  \n  \n    Malta \n    0.50 \n    21.17 \n    4134.0 \n  \n  \n    Croatia \n    0.11 \n    5.39 \n    4800.0 \n  \n\n\n\n\n\nRegarding imports, I observed that imports were reduced to only three countries: Finland, Belarus, and Russia. It is worth noting that imports from Japan increased by 80%, which is in contrast to the reduced exports by 26%. Lastly, I observed that imports from Portugal increased by 35 times.\n\n\nCode\n# select exports data and exclude aggregated entires\nagg <- c(\"Total\", \"European Union (27 countries)\", \"Euro Area (18 countries)\", \"Commonwealth of Independent States\", \"Offshore financial centers\", \"Other countries\")\ndt.import <- copy(dt[Type == \"Imports\" & !Country %in% agg])\ndt.import[, `Change, %` := round((`Q3/2022` / `Q3/2013` - 1) * 100, 1)]\n\n# get top 10 starting and last period countries by export\ntop_change <- tail(dt.import[, c(41, 4, 40, 42)][order(`Change, %`)], 5)\nlow_change <- head(dt.import[, c(41, 4, 40, 42)][order(`Change, %`)], 5)\n\n# get changes\ndt.changes <- rbind(low_change, top_change)\n\n# generate kable table\nkbl(dt.changes, caption = \"Top 5 largest positive and negative import changes\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n\n\n\n\nTop 5 largest positive and negative import changes\n \n  \n    Country \n    Q3/2013 \n    Q3/2022 \n    Change, % \n  \n \n\n  \n    Belarus \n    132.20 \n    35.61 \n    -73.1 \n  \n  \n    Russia \n    121.83 \n    41.64 \n    -65.8 \n  \n  \n    Finland \n    43.22 \n    28.25 \n    -34.6 \n  \n  \n    Denmark \n    38.90 \n    63.68 \n    63.7 \n  \n  \n    Japan \n    0.72 \n    1.31 \n    81.9 \n  \n  \n    Germany \n    43.94 \n    252.26 \n    474.1 \n  \n  \n    Luxembourg \n    1.58 \n    21.70 \n    1273.4 \n  \n  \n    Hong Kong \n    0.67 \n    9.97 \n    1388.1 \n  \n  \n    Malta \n    4.60 \n    91.82 \n    1896.1 \n  \n  \n    Portugal \n    0.59 \n    21.27 \n    3505.1 \n  \n\n\n\n\n\nOverall, this analysis highlights the importance of careful observation and analysis of data to uncover trends and patterns that can inform strategic decision-making for businesses and policymakers alike."
  },
  {
    "objectID": "posts/google-analytics-capstone/index.html#share",
    "href": "posts/google-analytics-capstone/index.html#share",
    "title": "Exports in Lithuania",
    "section": "Share",
    "text": "Share\nLet’s start from visualizing total export and import changes over time.\n\n\nCode\n# select data for plotting\ndt.plot.1 <- melt(dt, id.vars = c(\"Country\", \"Type\"), variable.name = \"Quarter\")\n\n# convert to datetime\ndt.plot.1[, Quarter := as.Date(as.yearqtr(Quarter, format = \"Q%q/%Y\"), frac = 1)]\n\n# colors for plotting\npal <- c(\"#6699ff\", \"#ff6666\")\n\n# create figure\nfig <- plot_ly(data = dt.plot.1[Type != \"Balance\" & Country == 'Total'],\n               type = 'scatter', mode = 'lines+markers',\n               x = ~Quarter, y = ~value, color = ~Type, colors = pal)\n# update layout\nfig <- fig %>% layout(title = \"Total import and export volumes over time\",\n                      xaxis = list(title = \"Date\"),\n                      yaxis = list (title = \"Volumne, M EUR\"))\nfig\n\n\n\n\n\n\nThere has been a significant increase in both total imports and exports, with a four-fold increase in imports and a three-fold increase in exports. However, during the first three quarters of 2020, there was a marked decline in both exports and imports, which can be attributed to the impact of Covid-19.\n\n\nCode\n# select data for plotting\ndt.plot.2 <- copy(dt.plot.1[Country %in% c(\"Total\", \"European Union (27 countries)\", \"Russia\", \"China\")])\n\n# reshape table\ndt.plot.2 <- dcast(dt.plot.2, Quarter+Type~Country, value.var = \"value\")\n\n# calculate share to Total values\ndt.plot.2[, `EU (27 countries) share, %` := round(`European Union (27 countries)` / Total * 100, 2)]\ndt.plot.2[, `Russia share, %` := round(`Russia` / Total * 100, 2)]\ndt.plot.2[, `China share, %` := round(`China` / Total * 100, 2)]\n\n# colors\neu.color <- 'rgb(22, 96, 167)'\nru.color <- 'rgb(205, 12, 24)'\nch.color <- 'rgb(0, 128, 0)'\n\n# create figure (imports)\nfig <- plot_ly(dt.plot.2[Type == 'Imports'],\n               x = ~Quarter, y = ~`EU (27 countries) share, %`,\n               name = 'EU (27 countries) imports', type = 'scatter', mode = 'lines',\n               line = list(color = eu.color, width = 4))\nfig <- fig %>% add_trace(y = ~`Russia share, %`,\n                         name = 'Russia imports',\n                         line = list(color = ru.color, width = 4))\nfig <- fig %>% add_trace(y = ~`China share, %`,\n                         name = 'China imports',\n                         line = list(color = ch.color, width = 4))\n# add exports\nfig <- fig %>% add_trace(x = dt.plot.2[Type == 'Exports']$Quarter,\n                         y = dt.plot.2[Type == 'Exports']$`EU (27 countries) share, %`,\n                         name = 'EU (27 countries) exports',\n                         line = list(color = eu.color, width = 4, dash = 'dash'))\nfig <- fig %>% add_trace(x = dt.plot.2[Type == 'Exports']$Quarter,\n                         y = dt.plot.2[Type == 'Exports']$`Russia share, %`,\n                         name = 'Russia exports',\n                         line = list(color = ru.color, width = 4, dash = 'dash'))\nfig <- fig %>% add_trace(x = dt.plot.2[Type == 'Exports']$Quarter,\n                         y = dt.plot.2[Type == 'Exports']$`China share, %`,\n                         name = 'China exports',\n                         line = list(color = ch.color, width = 4, dash = 'dash'))\n\n# update layout\nfig <- fig %>% layout(title = \"Total import and export volumes over time\",\n                      xaxis = list(title = \"Date\"),\n                      yaxis = list (title = \"Share to total, %\"))\nfig\n\n\n\n\n\n\nThe European Union has seen a significant increase in the proportion of imports in their total volume, which has increased by 50%. This means that the EU is becoming more reliant on imports and is potentially exporting less to other countries.\nWhen it comes to trade with Russia, both imports and exports have been declining steadily even before the start of the 2022 war. Prior to the war, Lithuania was a net importer with Russian trade. Surprisingly, tensions between China and Lithuania did not have a significant impact on their trade relationship, and the share of total imports from China increased almost 5 times.\nFinally let’s analyze how imports and exports were affected with Countries close to Russia.\n\n\nCode\n# countries to select\ncountry.list <- c(\"Kazakhstan\", \"Belarus\", \"Russia\", \"Turkey\", \"Offshore financial centers\")\n\n# select data for plotting\ndt.plot.3 <- copy(dt.plot.1[Country %in% country.list])\n\n# reshape table\ndt.plot.3 <- dcast(dt.plot.3, Quarter+Type~Country, value.var = \"value\")\n\n# reshape back\ndt.plot.3 <- melt(dt.plot.3, id.vars = c(\"Quarter\", \"Type\"), variable.name = \"Country\")\n\n# create new label\ndt.plot.3[, label := paste(Country, Type)]\n\n# color dictionary\ncolor.dict <- c(\"#C5AFA4\", \"#CC7E85\", \"#CF4D6F\", \"#A36D90\", \"#76818E\")\n\n# left figure\nfig1 <- plot_ly(data = dt.plot.3[Type == \"Imports\"],\n                x = ~Quarter, y = ~value, color=~label, colors = color.dict,\n                type = 'scatter', mode = 'lines+markers',\n                marker = list(line = list(width = 3)))\n\n# right figure\nfig2 <- plot_ly(data = dt.plot.3[Type == \"Exports\"],\n                x = ~Quarter, y = ~value, color=~label,\n                colors = color.dict,\n                type = 'scatter', mode = 'lines+markers',\n                line = list(dash = 'dot'),\n                marker = list(line = list(width = 3)))\n\nfig <- subplot(fig1, fig2, nrows = 2) %>% \n  layout(title = 'Exports and imports with countries close to Russia')\nfig\n\n\n\n\n\n\nNow, let’s turn our attention to how trade with countries close to Russia has been affected. Since the Russian invasion of Ukraine, imports and exports with Turkey and Kazakhstan have increased 3-5 times. This increase may be attributed to companies trying to circumvent sanctions to Russia through exports to Kazakhstan. It’s interesting to see how companies are adapting to changes in trade relationships and finding new opportunities to continue doing business."
  },
  {
    "objectID": "posts/google-analytics-capstone/index.html#act",
    "href": "posts/google-analytics-capstone/index.html#act",
    "title": "Exports in Lithuania",
    "section": "Act",
    "text": "Act\nIn conclusion, my analysis offers insights that could be utilized in evaluating the impact of historical events on Lithuania’s imports and exports. Based on the findings, several conclusions can be drawn:\n\nFirstly, the declines in imports and exports with Russia preceded the 2022 invasion to Ukraine. This finding suggests that the declining trade relationship between the two countries started since 2014 Crimea annexation.\nSecondly, the analysis revealed that political tensions over Taiwan did not have a substantial impact on exports to China.\nFinally, the data indicates that imports and exports to Kazakhstan have increased, potentially due to sanctions against Russia. This finding underscores the importance of considering the geopolitical context when imposing economical sanctions.\n\nOverall, the present study highlights the complexities of trade relationships between Lithuania and other countries."
  }
]
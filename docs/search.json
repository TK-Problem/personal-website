[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "One-Sample Binomial Test (Part 1)\n\n\n\n\n\n\n\nR\n\n\nPython\n\n\nStatistics\n\n\n\n\n\n\n\n\n\n\n\nMar 19, 2023\n\n\nTomas Kristijonas Uždavinys\n\n\n\n\n\n\n  \n\n\n\n\nExports in Lithuania\n\n\n\n\n\n\n\nR\n\n\nMacro Economy\n\n\nCoursera\n\n\n\n\n\n\n\n\n\n\n\nMar 11, 2023\n\n\nTomas Kristijonas Uždavinys\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tomas K. Uždavinys",
    "section": "",
    "text": "I am a physics scientist who became a Python developer and risk analyst. My principal expertise is in writing predictive models, web scraping and automation scripts. I also have a passion to explain complicated topics in an easy-to-understand manner."
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Tomas K. Uždavinys",
    "section": "Experience",
    "text": "Experience\nQuantitative Risk Analyst | SEB | 2022 JAN - Present\nFreelancer | MB “Kristaulitai” | 2019 JAN - Present"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Tomas K. Uždavinys",
    "section": "Education",
    "text": "Education\nKTH - Royal institute of technology | PhD, Photonics | 2014 SEP - 2018 AUG\nVilnius University | M.S., Optoelectronic materials and technology | 2012 SEP - 2014 AUG"
  },
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "Portfolio",
    "section": "",
    "text": "PhD thesis [download PDF]\nPhD defense [recording on YouTube]"
  },
  {
    "objectID": "portfolio.html#papers",
    "href": "portfolio.html#papers",
    "title": "Portfolio",
    "section": "Papers",
    "text": "Papers\n\nS. Marcinkevičius, T. K. Uždavinys, H. M. Foronda, D. A. Cohen, C. Weisbuch, and J. S. Speck, “Intervalley energy of GaN conduction band measured by femtosecond pump-probe spectroscopy”, Phys. Rev. B 94, 235205 (2016)\nT. K. Uždavinys, S. Marcinkevičius, J. H. Leach, K. R. Evans, and D. C. Look, “Photoexcited carrier trapping and recombination at Fe centers in GaN”, J. Appl. Phys. 119, 215706 (2016)\nR. Butté, L. Lahourcade, T. K. Uždavinys, G. Callsen, M. Mensi, M. Glauser, G. Rossbach, D. Martin, J-F. Carlin, S. Marcinkevičius and N. Grandjean, “Optical absorption edge broadening in thick In- GaN layers: Random alloy atomic disorder and growth mode induced fluctuations”, Appl. Phys. Lett., 112, 032106 (2018).\nT. K. Uždavinys, S. Marcinkevičius, M. Mensi, L. Lahourcade, J-F. Carlin, D. Martin, R. Butté and N. Grandjean, “Impact of surface morphology on properties of light emission in InGaN epilayers”, Appl. Phys. Express 11, 051004 (2018).\nR. Ivanov, S. Marcinkevičius, T. K. Uždavinys, L. Y. Kuritzky, S. Nakamura, and J. S. Speck, “Scanning near-field microscopy of carrier lifetimes in m-plane InGaN quantum wells”, Appl. Phys. Lett. 110, 031109 (2017).\nT. K. Uždavinys, D. L. Becerra, R. Ivanov, S. P. DenBaars, S. Nakamura, J. S. Speck, and S. Marcinkevičius, “Influence of well width fluctuations on recombination properties in semipolar InGaN quantum wells studied by time- and spatially-resolved near-field photoluminecence”, Opt. Mat. Express, 7(9), 3116-3123 (2017)."
  },
  {
    "objectID": "posts/binom-test-1/index.html",
    "href": "posts/binom-test-1/index.html",
    "title": "One-Sample Binomial Test (Part 1)",
    "section": "",
    "text": "The binomial test is a statistical test used to determine whether the proportion of cases in one of only two categories is equivalent to a pre-specified proportion. Categories could include the default rate of clients within the next 12 months, patients with high or low risk of heart disease, potential customers who are likely or not likely to make a purchase, or the rate of manufacturing defects. This widely used test finds applications in diverse fields, including credit risk, medicine, and manufacturing. It is also known to as the one-sample proportion test or test of one proportion.\nAs with all statistical tests, the binomial test has assumptions and conditions that must be met before applying it to real-life data:\n\nThe “success-failure” condition requires observing a minimum of n successes and n failures in the sample;\nobservations are independent, i.e. the occurrence of one event does not affect the probability of occurrence of the other.\n\nThe aim of this blog post is to showcase the ramifications of failing to meet “success-failure” condition critereon. Practical examples are coded in both R and Python languages.\n\nRPython\n\n\n\n\nCode\n# load libraries for blog post\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(data.table)\n\n\n\n\n\n\nCode\n# load packages for blog post\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nfrom scipy.stats import binom, norm\n\n# set style\nplt.style.use(\"ggplot\")"
  },
  {
    "objectID": "posts/binom-test-1/index.html#theory",
    "href": "posts/binom-test-1/index.html#theory",
    "title": "One-Sample Binomial Test (Part 1)",
    "section": "Theory",
    "text": "Theory\nSuppose that we have a sample where outcomes are binary - e.g. only “success” and “failure”. For the given sample, we would like to estimate the true proportion and also set up a statistical test to verify whether if the proportion is equal to some value, e.g. expected.\nFirst, we calculate a point estimate:\n\\[p = \\frac{n_s}{n}\\]\n, where \\(n\\) - sample size and \\(n_s\\) - the number of successful observations (or it can be the number of failures).\n\\[SE = \\sqrt{\\frac{p \\cdot (1 - p)}{n}}\\] , where \\(SE\\) is standard error. To perform a test, one first needs to derive a Null hypothesis:\n\\[H_0: p = p_0\\]\nand an alternative hypothesis:\n\none-sided \\(H_A: p < p_0\\) or \\(H_A: p > p_0\\),\ntwo-sided \\(H_A: p \\ne p_0\\).\n\nFinally, we needs to calculate \\(Z\\) statistics:\n\\[Z = \\frac{p_0-p}{SE}\\]\nObtaining the value of \\(Z\\) enables us to either compute confidence intervals (\\(CI\\)) or reject \\(H_0\\) in favor of \\(H_A\\)"
  },
  {
    "objectID": "posts/binom-test-1/index.html#success-failure-condition",
    "href": "posts/binom-test-1/index.html#success-failure-condition",
    "title": "One-Sample Binomial Test (Part 1)",
    "section": "“Success-failure” condition",
    "text": "“Success-failure” condition\nIn order to approximate any distribution as normal, the mean (\\(\\mu\\)) and standard deviation (\\(\\sigma\\)) must be known/calculated. For the Binomial distribution comprising \\(n\\) experiments and a probability of \\(p\\) normal distribution mean will be located at:\nTo approximate any distribution as normal, it is imperative to calculate the mean (\\(\\mu\\)) and standard deviation (\\(\\sigma\\)). For the Binomial distribution, which consists of a number of experiments \\(n\\) and a probability \\(p\\), the mean of the normal distribution is:\n\\[\\mu = n \\cdot p\\]\nand the standard deviation:\n\\[\\sigma = \\sqrt{n \\cdot p \\cdot (1 - p)}.\\]\nMeeting the “Success-Failure” condition is crucial to approximate Binomial distribution as Normal. Below, I present an instance of 50 Binomial events with varying probability rates of 5%, 30%, and 90%.\n\nbinomial vs. normal (R)error (R)binomial vs. normal (Python)error (Python)\n\n\n\n\nCode\n# probabilities\np <- c(0.05, 0.3, 0.9)\n\n# successes\nx <- 0:50\n\n# create data.table\ndt <- CJ(p, x)\n\n# add size column\ndt[, size := 50]\n\n# add binomial probability\ndt[, Binomial := dbinom(x, size=size, prob=p) * 100]\n\n# create label column\ndt[, label := paste0(\"Prob: \", round(p*100),\n                     \"%, exp. successes \", round(p*size),\n                     \" exp. failures \", round((1-p)*size))]\n\n# calculate mean and standard deviation\ndt[, mu := size * p]\ndt[, st.dev := sqrt(p * (1 - p) * size)]\n\n# get norm distribution\ndt[, Normal := dnorm(x, mean=mu, sd = st.dev) * 100]\n\n# convert to ordered factor\ndt[, label := factor(label, levels=c(\"Prob: 5%, exp. successes 2 exp. failures 48\",\n                                     \"Prob: 30%, exp. successes 15 exp. failures 35\",\n                                     \"Prob: 90%, exp. successes 45 exp. failures 5\" ))]\n\n# reshape for plotting\ndt.plot <- melt(dt, id.vars = c(\"x\", \"label\"),\n                measure.vars = c(\"Binomial\", \"Normal\"),\n                variable.name = c(\"Type\"),\n                value.name = c('prob'))\n\n# create figure\nfig <- ggplot(dt.plot, aes(x, prob, color=Type)) + geom_point() + facet_wrap(~label, ncol = 1) + ylab(\"Probability, %\")\nfig\n\n\n\n\n\n\n\n\n\nCode\n# calculate error (use data.table from previous code chunk)\ndt[, Error := Binomial - Normal]\n\n# create figure\nfig <- ggplot(dt, aes(x, Error)) + geom_point() + facet_wrap(~label, ncol = 1) + ylab(\"Error (binom. - norm.), %\")\nfig\n\n\n\n\n\n\n\n\n\nCode\n# probabilities\np = [0.05, 0.3, 0.9]\n\n# successes\nx = np.arange(51)\n\n# create DataFrame with all combinations\ndf_1 = pd.DataFrame({'p': p})\ndf_2 = pd.DataFrame({'x': x})\n\n# create key for joining\ndf_1['key'] = 0\ndf_2['key'] = 0\n\n# perform cross join\ndf = df_1.merge(df_2, on='key', how='outer')\n\n# drop key column\ndel df['key']\n\n# add size value\ndf['size'] = 50\n\n# calculate binomial probability\ndf['Binomial'] = binom.pmf(df['x'], df['size'], df['p']) * 100\n \n# calculate mean and standard deviation\ndf['mu'] = df['size'] * df['p']\ndf['se'] = np.sqrt(df['p'] * (1 - df['p']) / df['size'])\ndf['std'] = np.sqrt(df['p'] * (1 - df['p']) * df['size'])\n\n# get norm distribution\ndf['Normal'] = df.apply(lambda x: norm.pdf(x['x'], x['mu'], x['std']) * 100, axis = 1)\n\n# create figure\nfig, ax = plt.subplots(3, 1, sharey=True)\n\n# iterate over probabilities\nfor i, _p in enumerate(p):\n  # select data for plotting\n  dt_plot = df.loc[df['p'] == _p].copy()\n  \n  # plot binomial and normal distributions\n  ax[i].plot(dt_plot['x'], dt_plot['Binomial'], \"o\", label='Binomial');\n  ax[i].plot(dt_plot['x'], dt_plot['Normal'], \"-\", label='Normal', linewidth=3);\n  \n  # add sub titles\n  ax[i].set_title(f\"Prob. {_p*100:.0f}% expected {50*_p:.0f} successes and {50*(1-_p):.0f} failures\", fontsize=8);\n\n# add labels\nax[1].set_ylabel(\"Probability, %\");\nax[2].set_xlabel(\"x\");\n\n# add legend and white background\nlegend = ax[1].legend(frameon = 1);\nframe = legend.get_frame();\nframe.set_color('white');\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nCode\n# calculate error (use DataFrame from previous code chunk)\ndf['Error'] = df.Binomial - df.Normal\n\n# create figure\nfig, ax = plt.subplots(3, 1, sharey=True)\n\n# iterate over probabilities\nfor i, _p in enumerate(p):\n  # select data for plotting\n  dt_plot = df.loc[df['p'] == _p]\n  \n  # plot binomial and normal distributions\n  ax[i].plot(dt_plot['x'], dt_plot['Error'], \"o\", color='k', markersize=3);\n  \n  # add sub titles\n  ax[i].set_title(f\"Prob. {_p*100:.0f}% expected {50*_p:.0f} successes and {50*(1-_p):.0f} failures\", fontsize=8);\n  \n# adjust limits for better readability\nax[0].set_ylim(-4.9, 4.9)\n\n# add labels\n\n\n(-4.9, 4.9)\n\n\nCode\nax[1].set_ylabel(\"Probability, %\")\nax[2].set_xlabel(\"x\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe first thing to notice is that the “Success-Failure” criterion is only met for the p=30% case. In tabs error one can see that approximation error, i.e. the difference between Binomial probability and Normal distribution approximations, is above 2% for the \\(p=5\\%\\) and \\(p=90\\%\\) examples."
  },
  {
    "objectID": "posts/binom-test-1/index.html#estimating-approximation-error",
    "href": "posts/binom-test-1/index.html#estimating-approximation-error",
    "title": "One-Sample Binomial Test (Part 1)",
    "section": "Estimating approximation error",
    "text": "Estimating approximation error\nThere are a different way to calculate approximation error dependence on sample size. Let’s establish 3 types of probabilities:\n\n\\(p_1\\) we would observe more than expected number of occurrences,\n\\(p_2\\) we would observe expected number of occurrences,\n\\(p_3\\) we would observe less than expected number of occurrences.\n\nWe have to be mindful, when comparing discrete binomial distribution with a continuous normal distribution. In examples bellow, we can compare areas under the curve for both distributions using interactive charts by plotly library/package. First I create a function to visualize both pint cand cumulative probabilities using interactive charts.\n\nplot_ly function (R)plotly function (Python)\n\n\n\n\nCode\nPlotDistributions <- function(prob, size){\n  # create observation vector\n  x <- 0:(size*prob*3)\n  \n  # get probabilities for both binomial and norm distributions\n  y.binom <- dbinom(x, size=size, prob=prob) * 100\n  y.norm <- dnorm(x, mean=size * prob, sd = sqrt(prob * (1 - prob) * size)) * 100\n  \n  # create data table for plotting\n  dt <- data.table(x = x,\n                   prob.binom = y.binom,\n                   prob.norm = y.norm)\n  \n  # add columns with hover information\n  dt[, text.1 := paste0('Point estimate probability<br>to observer exactly ', x,\n                        ' events is ', round(y.binom, 3), \"%\")]\n  dt[, text.2 := paste0('Point estimate probability<br>to observer exactly ', x,\n                        ' events is ', round(y.norm, 3), \"%\")]\n  dt[, text.3 := paste0('Point estimate error<br>to observer exactly ', x,\n                        ' events is ', round(y.binom - y.norm, 3), \"%\")]\n  # create figure\n  fig <- plot_ly(data = dt, type = 'scatter', mode = 'lines')\n  \n  # add traces\n  fig <- fig %>% add_trace(x = ~x, y = ~prob.norm, text = ~text.1,\n                           name = 'Normal',mode = 'lines',\n                           hoverinfo = 'text',\n                           line = list(color = \"#FF6666\", width = 5))\n  fig <- fig %>% add_trace(x = ~x, y = ~prob.binom, text = ~text.2,\n                           name = 'Binomial',mode = 'markers',\n                           hoverinfo = 'text',\n                           marker = list(color = \"#3399FF\", size = 12))\n  fig <- fig %>% add_trace(x = ~x, y = ~(prob.binom-prob.norm), text = ~text.3,\n                           name = 'Error',mode = 'lines+markers',\n                           hoverinfo = 'text',\n                           line = list(color = \"black\", width = 5),\n                           marker = list(color = \"black\", size = 12),\n                           visible = \"legendonly\") \n  \n  # update layout\n  fig <- fig %>% layout(title = paste0(\"p = \", round(prob*100), \"%, \", size, \" trials\"),\n                        xaxis = list(title = \"Observations\"),\n                        yaxis = list (title = \"Probability, %\"),\n                        hovermode = \"x unified\",\n                        legend=list(title=list(text='<b> Distributions </b>')))\n  # return figure\n  return(fig)\n}\n\n\n\n\n\n\nCode\n# create function for plotting distributions\ndef plot_distributions(prob, size):\n  # create observation vector\n  x = np.arange(int(size*prob*3))\n  \n  # get probabilities for both binomial and norm distributions\n  y_binom = binom.pmf(x, n=size, p=prob) * 100\n  \n  # calculate variance and sigma\n  variance = size * prob * (1 - prob)\n  sigma = np.sqrt(variance)\n  \n  y_norm = norm.pdf(x, loc = size * prob, scale = sigma) * 100\n  \n  # generate Data.Frame\n  df = pd.DataFrame({'x': x, 'binom': y_binom, 'norm': y_norm})\n  \n  # calculate error\n  df['error'] = df.binom - df.norm\n  error = df.binom - df.norm\n  \n  # generate hover messages\n  df['text_1'] = df.apply(lambda x: f'Point estimate probability<br>to observer exactly {x[\"x\"]:.0f} events is {x[\"binom\"]:.3f}%', axis = 1)\n  df['text_2'] = df.apply(lambda x: f'Point estimate probability<br>to observer exactly {x[\"x\"]:.0f} events is {x[\"norm\"]:.3f}%', axis = 1)\n  df['text_3'] = df.apply(lambda x: f'Point estimate error<br>to observer exactly {x[\"x\"]:.0f} events is {x[\"error\"]:.3f}%', axis = 1)\n  \n  # create figure\n  fig = go.Figure()\n  fig.add_trace(go.Scatter(x=x, y=y_norm, text = df['text_1'].values,\n                           mode='lines', name='Normal', hoverinfo = 'text',\n                           line=dict(color='#FF6666', width=5)))\n  fig.add_trace(go.Scatter(x=x, y=y_binom, text = df['text_2'].values,\n                           mode='markers', name='Binomial', hoverinfo = 'text',\n                           marker=dict(color='#3399FF', size=12)))\n  fig.add_trace(go.Scatter(x=x, y=error, text = df['text_3'].values,\n                           mode='markers', name='Error', hoverinfo = 'text',\n                           marker=dict(color='black', size=12),\n                           visible = \"legendonly\"))\n                           \n  # Edit the layout\n  fig.update_layout(title=f\"p = {prob*100:.1f}%, {size} trials\",\n                    xaxis_title='Observations',\n                    yaxis_title='Probability, %',\n                    template=\"ggplot2\",\n                    hovermode=\"x unified\")\n                   \n  return fig\n\n\n\n\n\nNext I provide examples using different probabilities.\n\n5% (R)1% (R)0.5% (Python)0.0=1% (Python)\n\n\n\n\nCode\n# return figure\nPlotDistributions(0.05, 200)\n\n\n\n\n\n\n\n\n\n\nCode\n# return figure\nPlotDistributions(0.01, 500)\n\n\n\n\n\n\n\n\n\n\nCode\n# use python helper function from above\nfig = plot_distributions(0.005, 500)\nfig\n\n\n\n                        \n                                            \n\n\n\n\n\n\nCode\n# use python helper function from above\nfig = plot_distributions(0.001, 2000)\nfig\n\n\n\n                        \n                                            \n\n\n\n\n\nLet’s taken hypothetical model of 1%, i.e. we expect to have 1% manufacturing defects or 1% of clients in our portfolio will fail to meet their credit obligations. For this hypothetical model to meet “Success-Failure” condition we would need to collect at least 1000 observations, i.e. to manufacture 1000 devices or issue credit to 1000 obligatory. Let’s compare 3 probabilities calculated using binomial and normal distribution approximation:\nIn all 3 cases, we need to calculated expected number of occurrences \\(n \\cdot p\\). Let’s investigate sample sizes raging from 100 to 2000.\nFrom the given example, we can ratios between probabilities for all 3 cases.\n\nRPython\n\n\n\n\nCode\n# create vector with different sample sizes\nsampleSizes <- seq(100, 2000, 100)\n\n# create data.table for p = 0.01, i.e. 1%\ndt <- data.table(N = sampleSizes, p = 0.02)\n\n# calculate expected number of observations and standard deviation\ndt[, mu := N * p]\ndt[, std := sqrt(p * (1 - p) * N)]\n\n# calculate probabilities of observing:\n# 1. less than the expected number of observations\n# 2. exactly the expected number of observations\n# 3. more than the expected number of observations\ndt[, binom.1 := pbinom(mu-1, size=N, prob=p)]\ndt[, binom.2 := dbinom(mu, size=N, prob=p)]\ndt[, binom.3 := 1 - pbinom(mu, size=N, prob=p)]\n\n# same but for normal distribution\ndt[, norm.1 := pnorm(mu-1, mean = mu, sd = std)]\ndt[, norm.2 := pnorm(mu+1, mean = mu, sd = std) - pnorm(mu-1, mean = mu, sd = std)]\ndt[, norm.3 := 1 - pnorm(mu+1, mean = mu, sd = std)]\n\n# calculate errors\ndt[, error.left := binom.1/norm.1]\ndt[, error.right := binom.3/norm.3]\n\n\n\n\n\n\nCode\n# load packages for blog post"
  },
  {
    "objectID": "posts/binom-test-1/index.html#independent-observations",
    "href": "posts/binom-test-1/index.html#independent-observations",
    "title": "One-Sample Binomial Test (Part 1)",
    "section": "Independent observations",
    "text": "Independent observations"
  },
  {
    "objectID": "posts/binom-test-1/index.html#references",
    "href": "posts/binom-test-1/index.html#references",
    "title": "One-Sample Binomial Test (Part 1)",
    "section": "References",
    "text": "References\nContent for this blog post was prepared using following references:\n\nhttps://statistics.laerd.com/spss-tutorials/binomial-test-using-spss-statistics.php\nhttp://mlwiki.org/index.php/Binomial_Proportion_Tests\nhttps://sites.ualberta.ca/~lkgray/uploads/7/3/6/2/7362679/slides_-_binomialproportionaltests.pdf\nhttps://www.technologynetworks.com/informatics/articles/the-binomial-test-366022\nhttps://towardsdatascience.com/turning-a-two-sample-event-rate-test-into-a-one-sample-binomial-test-23fbfb9d1df6\nhttps://www.studysmarter.us/explanations/math/statistics/binomial-hypothesis-test/\nhttps://www.statology.org/success-failure-condition/\nhttps://towardsdatascience.com/bernoulli-and-binomial-random-variables-d0698288dd36\nhttps://ubc-mds.github.io/DSCI_551_stat-prob-dsci/lectures/simulation.html\nhttps://math.stackexchange.com/questions/1978138/probability-of-x-red-balls-when-drawing-y-balls-from-a-red-and-b-green-balls"
  },
  {
    "objectID": "posts/google-analytics-capstone/index.html",
    "href": "posts/google-analytics-capstone/index.html",
    "title": "Exports in Lithuania",
    "section": "",
    "text": "Hello and welcome to my first blog post on Quarto! As a part of my Google Data Analytics specialization course capstone project, I have created this blog. In this post, I will be exploring the changes in historical exports and imports of Lithuania over time, using the 6-step framework presented in the course. I hope you enjoy reading about my findings and analysis. Let’s begin!"
  },
  {
    "objectID": "posts/google-analytics-capstone/index.html#ask",
    "href": "posts/google-analytics-capstone/index.html#ask",
    "title": "Exports in Lithuania",
    "section": "Ask",
    "text": "Ask\nBefore diving into data processing and visualization, it’s essential to take note of the following key events: the Covid-19 pandemic since spring 2020, the strained relationship between China and Lithuania due to the Taiwan question, and the Russian invasion of Ukraine in 2022.\nThe Covid-19 pandemic has brought unprecedented changes to the global economy, and Lithuania was no exception. The outbreak caused major disruptions in global trade, resulting in a decline in demand for Lithuanian goods and services. On the other hand, Lithuania’s relationship with China has been deteriorating due to the Taiwan question. This has led to a decrease in exports to China, one of Lithuania’s top trading partners.\nThe Russian invasion of Ukraine in 2022 has also had a significant impact on Lithuania’s trade patterns. The conflict has resulted in the imposition of economic sanctions on Russia, affecting Lithuania’s trade with its Eastern neighbor. The situation is still developing, and it will be interesting to see how Lithuania’s trade with Russia evolves in the coming years."
  },
  {
    "objectID": "posts/google-analytics-capstone/index.html#prepare",
    "href": "posts/google-analytics-capstone/index.html#prepare",
    "title": "Exports in Lithuania",
    "section": "Prepare",
    "text": "Prepare\nThe data was downloaded from the Lithuanian National website in an Excel file format. You can also find the same file in my blog’s Github repo. It was then loaded into the R environment using the tidyverse library and converted to data.table format.\n\n\nCode\n# load libraries\nlibrary(readxl)\nlibrary(data.table)\nlibrary(kableExtra)\nlibrary(plotly)\nlibrary(zoo)\n\n# read data from excel\ndt <- read_excel(\"lb_data.xlsx\", sheet = 1, range = \"A13:AN201\")\n\n# convert to data.table object\ndt <- data.table(dt)\n\n# rename columns for convinience\nsetnames(dt, c(\"...1\"), \"Type\")\n\n# shift columns to get correct names\ndt[, Country := rep(dt[seq(1, nrow(dt), 4), Type], each = 4)]\ndt <- dt[!(seq(1, nrow(dt), 4))]\n\n# generate table with first few rows and columns\nkbl(dt[1:6, c(41, 1, 38, 39, 40)]) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n\n\n\n\n \n  \n    Country \n    Type \n    Q1/2022 \n    Q2/2022 \n    Q3/2022 \n  \n \n\n  \n    Total \n    Exports \n    3666.97 \n    4230.51 \n    4615.79 \n  \n  \n    Total \n    Imports \n    2417.61 \n    2585.59 \n    2814.54 \n  \n  \n    Total \n    Balance \n    1249.36 \n    1644.92 \n    1801.25 \n  \n  \n    European Union (27 countries) \n    Exports \n    2712.50 \n    3182.83 \n    3343.46 \n  \n  \n    European Union (27 countries) \n    Imports \n    1646.39 \n    1887.25 \n    2026.76 \n  \n  \n    European Union (27 countries) \n    Balance \n    1066.11 \n    1295.58 \n    1316.70 \n  \n\n\n\n\n\nIn the table above, you can see the total exports and imports of all countries, as well as those of the European Union’s (27 countries) for the three most recent quarters. Even before data cleaning and preparation, a visual analysis shows that a majority of exports and imports go to EU countries. Data is available about 41 unique countries."
  },
  {
    "objectID": "posts/google-analytics-capstone/index.html#process",
    "href": "posts/google-analytics-capstone/index.html#process",
    "title": "Exports in Lithuania",
    "section": "Process",
    "text": "Process\nFor this project, we didn’t need to do much data cleaning or processing since there were no missing values or unknown formats. However, we did make some minor formatting adjustments in the Prepare section. To keep things simple, I decided not to split this section into different parts."
  },
  {
    "objectID": "posts/google-analytics-capstone/index.html#analyze",
    "href": "posts/google-analytics-capstone/index.html#analyze",
    "title": "Exports in Lithuania",
    "section": "Analyze",
    "text": "Analyze\nAfter formatting and sorting the data, I investigated export changes of top 10 largest export destinations in 2003 Q3. Exports across European countries saw a substantial increase, with some countries experiencing growth rates of between 200-700%, exports to Belarus and Russia dropped significantly by 60% and 50%, respectively.\n\n\nCode\n# select exports data and exclude aggregated entires\nagg <- c(\"Total\", \"European Union (27 countries)\", \"Euro Area (18 countries)\", \"Commonwealth of Independent States\", \"Offshore financial centers\", \"Other countries\")\ndt.export <- copy(dt[Type == \"Exports\" & !Country %in% agg])\ndt.export[, `Change, %` := round((`Q3/2022` / `Q3/2013` - 1) * 100, 1)]\n# get top 10 starting and last period countries by export\nstart <- tail(dt.export[, c(41, 4, 40)][order(`Q3/2013`)], 10)\n# generate kable table\nkbl(start, caption = \"Top 10 largest export destinations in 2013 Q3\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n\n\n\n\nTop 10 largest export destinations in 2013 Q3\n \n  \n    Country \n    Q3/2013 \n    Q3/2022 \n  \n \n\n  \n    United Kingdom \n    44.43 \n    261.90 \n  \n  \n    Netherlands \n    44.60 \n    313.90 \n  \n  \n    Norway \n    46.59 \n    115.63 \n  \n  \n    France \n    47.51 \n    380.13 \n  \n  \n    Denmark \n    61.80 \n    214.14 \n  \n  \n    Latvia \n    78.22 \n    181.07 \n  \n  \n    Poland \n    80.27 \n    209.38 \n  \n  \n    Belarus \n    120.38 \n    45.89 \n  \n  \n    Germany \n    148.49 \n    637.61 \n  \n  \n    Russia \n    323.90 \n    154.09 \n  \n\n\n\n\n\nI found it interesting to observe that out of the 41 countries with known data, there were export reductions in only four countries: Egypt, Russia, Belarus, and Japan. Furthermore, I noticed that the largest export changes were seen in countries with relatively small exports in 2003 Q3, such as Croatia and Malta, whose exports increased 40 times. It’s worth noting that Canada, a large economy, also saw a significant increase in exports, which grew almost 30 times.\n\n\nCode\n# get top 10 starting and last period countries by export\ntop_change <- tail(dt.export[, c(41, 4, 40, 42)][order(`Change, %`)], 5)\nlow_change <- head(dt.export[, c(41, 4, 40, 42)][order(`Change, %`)], 5)\n\n# get changes\ndt.changes <- rbind(low_change, top_change)\n\n# generate kable table\nkbl(dt.changes, caption = \"Top 5 largest positive and negative export changes\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n\n\n\n\nTop 5 largest positive and negative export changes\n \n  \n    Country \n    Q3/2013 \n    Q3/2022 \n    Change, % \n  \n \n\n  \n    Egypt \n    4.65 \n    0.94 \n    -79.8 \n  \n  \n    Belarus \n    120.38 \n    45.89 \n    -61.9 \n  \n  \n    Russia \n    323.90 \n    154.09 \n    -52.4 \n  \n  \n    Japan \n    1.64 \n    1.21 \n    -26.2 \n  \n  \n    India \n    2.52 \n    3.03 \n    20.2 \n  \n  \n    Bulgaria \n    0.76 \n    13.92 \n    1731.6 \n  \n  \n    Canada \n    0.38 \n    11.62 \n    2957.9 \n  \n  \n    Romania \n    0.70 \n    27.03 \n    3761.4 \n  \n  \n    Malta \n    0.50 \n    21.17 \n    4134.0 \n  \n  \n    Croatia \n    0.11 \n    5.39 \n    4800.0 \n  \n\n\n\n\n\nRegarding imports, I observed that imports were reduced to only three countries: Finland, Belarus, and Russia. It is worth noting that imports from Japan increased by 80%, which is in contrast to the reduced exports by 26%. Lastly, I observed that imports from Portugal increased by 35 times.\n\n\nCode\n# select exports data and exclude aggregated entires\nagg <- c(\"Total\", \"European Union (27 countries)\", \"Euro Area (18 countries)\", \"Commonwealth of Independent States\", \"Offshore financial centers\", \"Other countries\")\ndt.import <- copy(dt[Type == \"Imports\" & !Country %in% agg])\ndt.import[, `Change, %` := round((`Q3/2022` / `Q3/2013` - 1) * 100, 1)]\n\n# get top 10 starting and last period countries by export\ntop_change <- tail(dt.import[, c(41, 4, 40, 42)][order(`Change, %`)], 5)\nlow_change <- head(dt.import[, c(41, 4, 40, 42)][order(`Change, %`)], 5)\n\n# get changes\ndt.changes <- rbind(low_change, top_change)\n\n# generate kable table\nkbl(dt.changes, caption = \"Top 5 largest positive and negative import changes\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n\n\n\n\nTop 5 largest positive and negative import changes\n \n  \n    Country \n    Q3/2013 \n    Q3/2022 \n    Change, % \n  \n \n\n  \n    Belarus \n    132.20 \n    35.61 \n    -73.1 \n  \n  \n    Russia \n    121.83 \n    41.64 \n    -65.8 \n  \n  \n    Finland \n    43.22 \n    28.25 \n    -34.6 \n  \n  \n    Denmark \n    38.90 \n    63.68 \n    63.7 \n  \n  \n    Japan \n    0.72 \n    1.31 \n    81.9 \n  \n  \n    Germany \n    43.94 \n    252.26 \n    474.1 \n  \n  \n    Luxembourg \n    1.58 \n    21.70 \n    1273.4 \n  \n  \n    Hong Kong \n    0.67 \n    9.97 \n    1388.1 \n  \n  \n    Malta \n    4.60 \n    91.82 \n    1896.1 \n  \n  \n    Portugal \n    0.59 \n    21.27 \n    3505.1 \n  \n\n\n\n\n\nOverall, this analysis highlights the importance of careful observation and analysis of data to uncover trends and patterns that can inform strategic decision-making for businesses and policymakers alike."
  },
  {
    "objectID": "posts/google-analytics-capstone/index.html#share",
    "href": "posts/google-analytics-capstone/index.html#share",
    "title": "Exports in Lithuania",
    "section": "Share",
    "text": "Share\nLet’s start from visualizing total export and import changes over time.\n\n\nCode\n# select data for plotting\ndt.plot.1 <- melt(dt, id.vars = c(\"Country\", \"Type\"), variable.name = \"Quarter\")\n\n# convert to datetime\ndt.plot.1[, Quarter := as.Date(as.yearqtr(Quarter, format = \"Q%q/%Y\"), frac = 1)]\n\n# colors for plotting\npal <- c(\"#6699ff\", \"#ff6666\")\n\n# create figure\nfig <- plot_ly(data = dt.plot.1[Type != \"Balance\" & Country == 'Total'],\n               type = 'scatter', mode = 'lines+markers',\n               x = ~Quarter, y = ~value, color = ~Type, colors = pal)\n# update layout\nfig <- fig %>% layout(title = \"Total import and export volumes over time\",\n                      xaxis = list(title = \"Date\"),\n                      yaxis = list (title = \"Volumne, M EUR\"))\nfig\n\n\n\n\n\n\nThere has been a significant increase in both total imports and exports, with a four-fold increase in imports and a three-fold increase in exports. However, during the first three quarters of 2020, there was a marked decline in both exports and imports, which can be attributed to the impact of Covid-19.\n\n\nCode\n# select data for plotting\ndt.plot.2 <- copy(dt.plot.1[Country %in% c(\"Total\", \"European Union (27 countries)\", \"Russia\", \"China\")])\n\n# reshape table\ndt.plot.2 <- dcast(dt.plot.2, Quarter+Type~Country, value.var = \"value\")\n\n# calculate share to Total values\ndt.plot.2[, `EU (27 countries) share, %` := round(`European Union (27 countries)` / Total * 100, 2)]\ndt.plot.2[, `Russia share, %` := round(`Russia` / Total * 100, 2)]\ndt.plot.2[, `China share, %` := round(`China` / Total * 100, 2)]\n\n# colors\neu.color <- 'rgb(22, 96, 167)'\nru.color <- 'rgb(205, 12, 24)'\nch.color <- 'rgb(0, 128, 0)'\n\n# create figure (imports)\nfig <- plot_ly(dt.plot.2[Type == 'Imports'],\n               x = ~Quarter, y = ~`EU (27 countries) share, %`,\n               name = 'EU (27 countries) imports', type = 'scatter', mode = 'lines',\n               line = list(color = eu.color, width = 4))\nfig <- fig %>% add_trace(y = ~`Russia share, %`,\n                         name = 'Russia imports',\n                         line = list(color = ru.color, width = 4))\nfig <- fig %>% add_trace(y = ~`China share, %`,\n                         name = 'China imports',\n                         line = list(color = ch.color, width = 4))\n# add exports\nfig <- fig %>% add_trace(x = dt.plot.2[Type == 'Exports']$Quarter,\n                         y = dt.plot.2[Type == 'Exports']$`EU (27 countries) share, %`,\n                         name = 'EU (27 countries) exports',\n                         line = list(color = eu.color, width = 4, dash = 'dash'))\nfig <- fig %>% add_trace(x = dt.plot.2[Type == 'Exports']$Quarter,\n                         y = dt.plot.2[Type == 'Exports']$`Russia share, %`,\n                         name = 'Russia exports',\n                         line = list(color = ru.color, width = 4, dash = 'dash'))\nfig <- fig %>% add_trace(x = dt.plot.2[Type == 'Exports']$Quarter,\n                         y = dt.plot.2[Type == 'Exports']$`China share, %`,\n                         name = 'China exports',\n                         line = list(color = ch.color, width = 4, dash = 'dash'))\n\n# update layout\nfig <- fig %>% layout(title = \"Total import and export volumes over time\",\n                      xaxis = list(title = \"Date\"),\n                      yaxis = list (title = \"Share to total, %\"))\nfig\n\n\n\n\n\n\nThe European Union has seen a significant increase in the proportion of imports in their total volume, which has increased by 50%. This means that the EU is becoming more reliant on imports and is potentially exporting less to other countries.\nWhen it comes to trade with Russia, both imports and exports have been declining steadily even before the start of the 2022 war. Prior to the war, Lithuania was a net importer with Russian trade. Surprisingly, tensions between China and Lithuania did not have a significant impact on their trade relationship, and the share of total imports from China increased almost 5 times.\nFinally let’s analyze how imports and exports were affected with Countries close to Russia.\n\n\nCode\n# countries to select\ncountry.list <- c(\"Kazakhstan\", \"Belarus\", \"Russia\", \"Turkey\", \"Offshore financial centers\")\n\n# select data for plotting\ndt.plot.3 <- copy(dt.plot.1[Country %in% country.list])\n\n# reshape table\ndt.plot.3 <- dcast(dt.plot.3, Quarter+Type~Country, value.var = \"value\")\n\n# reshape back\ndt.plot.3 <- melt(dt.plot.3, id.vars = c(\"Quarter\", \"Type\"), variable.name = \"Country\")\n\n# create new label\ndt.plot.3[, label := paste(Country, Type)]\n\n# color dictionary\ncolor.dict <- c(\"#C5AFA4\", \"#CC7E85\", \"#CF4D6F\", \"#A36D90\", \"#76818E\")\n\n# left figure\nfig1 <- plot_ly(data = dt.plot.3[Type == \"Imports\"],\n                x = ~Quarter, y = ~value, color=~label, colors = color.dict,\n                type = 'scatter', mode = 'lines+markers',\n                marker = list(line = list(width = 3)))\n\n# right figure\nfig2 <- plot_ly(data = dt.plot.3[Type == \"Exports\"],\n                x = ~Quarter, y = ~value, color=~label,\n                colors = color.dict,\n                type = 'scatter', mode = 'lines+markers',\n                line = list(dash = 'dot'),\n                marker = list(line = list(width = 3)))\n\nfig <- subplot(fig1, fig2, nrows = 2) %>% \n  layout(title = 'Exports and imports with countries close to Russia')\nfig\n\n\n\n\n\n\nNow, let’s turn our attention to how trade with countries close to Russia has been affected. Since the Russian invasion of Ukraine, imports and exports with Turkey and Kazakhstan have increased 3-5 times. This increase may be attributed to companies trying to circumvent sanctions to Russia through exports to Kazakhstan. It’s interesting to see how companies are adapting to changes in trade relationships and finding new opportunities to continue doing business."
  },
  {
    "objectID": "posts/google-analytics-capstone/index.html#act",
    "href": "posts/google-analytics-capstone/index.html#act",
    "title": "Exports in Lithuania",
    "section": "Act",
    "text": "Act\nIn conclusion, my analysis offers insights that could be utilized in evaluating the impact of historical events on Lithuania’s imports and exports. Based on the findings, several conclusions can be drawn:\n\nFirstly, the declines in imports and exports with Russia preceded the 2022 invasion to Ukraine. This finding suggests that the declining trade relationship between the two countries started since 2014 Crimea annexation.\nSecondly, the analysis revealed that political tensions over Taiwan did not have a substantial impact on exports to China.\nFinally, the data indicates that imports and exports to Kazakhstan have increased, potentially due to sanctions against Russia. This finding underscores the importance of considering the geopolitical context when imposing economical sanctions.\n\nOverall, the present study highlights the complexities of trade relationships between Lithuania and other countries."
  }
]